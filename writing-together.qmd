---
title: "Writing Together trough resolve: A Bridge Between Analysis and Synthesis"
author: "Michel Nivard"
date: "2025-04-01"
abstract: "In today's data-centric world, writing has evolved beyond static pages. Many of us rely on code-enabled documents (think `.ipynb` notebooks or Quarto `.qmd` files) to combine text, data analysis, and visuals in one place. Yet these documents can alienate those who don't code. Those who shape ideas, refine language, or provide domain expertise—without touching the code: those who synthesize. Resolve was developed to lower the barrier for non-coders, the synthesists, while keepig the dociment, and the text close to the source data, facilitating the analists. Resolve is an online texteditor developed with one goal in mind:  broadening access to collaborative scientific and creative writing for everyone."
format: html
jupyter: ir
bibliography: references.bib
---

# 1. Scientific writing, is changing

For centuries, writing was linear: authors wrote prose, revisers edited text, and printers reproduced static pages. Then computers arrived, and documents became far more dynamic. Digitisation eased revision, and collaboration, email further sped up collaboration, obviating the need for any physical transfer from one collaborator to another.

Digitisation further brought writing, and data analysis to a single place, our PC as are portal to our writings and our data analysis. Though specialized tools evolved separately and for most to this day, data analysis and writing are isolated activities.

## 1.2 Literate Programming for All

 **Knuth** introduced the idea of literate programming decades ago: the premise that our code and our explanation shouldn’t live in separate corners. Now, with data-driven science at the forefront, there’s a dire need for writers, editors, domain experts, journalists—to join the conversation without drowning in code. By bridging that gap, we empower more voices and guarantee a more inclusive final results. Trough literate programming enables **mixing words and data**— in science and journalism.

## 1.3 The Rise of Code-Enabled Authoring

Many of today's data analysis tools, like Jupyter notebooks (`.ipynb`) and Quarto (`.qmd`) let us weave code and and text into a single document. Literate programming, merges narrative and computation, letting readers follow the logic behind every figure and result. It's a powerful concept: you write your story while code chunks generate your tables, plots, or transformations in real time. 

## 1.4 Analysis, balanced by synthesis.

Literate programming, as conceived currently, can still **intimidate or exclude** those who: - Don’t code daily (or at all). - Don’t know why `import numpy as np` or `library(ggplot2)` feature in the main text. Literate prograamig takes place in code oriented text editors, or in explicit programming tools like integrated development environemnts (IDEs). Its and effort to meet halfway between data an prose, but why meet halfway when we can have it both ways?

Data analysis isn't the only analysis that goes into scientific production, and its fundamentally limited when offered without synthesis. In the humanities analysis is understood differnetly, as aprt of a wholistic process, a method: 

"The art of arranging a series of thoughts properly, either for discovering the truth when we do not know it, or for proving to others what we already know, can generally be called method. Hence there are two kinds of method, one for discovering the truth, which is known as analysis, or the method of resolution, and which can also be called the method of discovery. The other is for making the truth understood by others once it is found. This is known as synthesis, or the method of composition, and can also be called the method of instruction." [@arnauld1996]

Literate programming brings code and prose closer together, but literate programming still happens in technical squarely in the domain of the analyst, we need to meet those who synthesis for a living, the synthesist, in their confortzone: the text editor.

## 1.5 A Need for a Bridge

We don’t necessarily want to replace notebooks or computational markup languages like quarto. They already do a superb job of uniting text and analysis. Instead, I we nned a **gentle wrapper**—a place where non-coders can come in, highlight a paragraph, reorganize headings, or refine language. Think a “word processor layer” over literate programming. The file remains a `.ipynb` notebook at heart, but collaborators edits trough a friendlier interface, and interface that offers the creature comfort of a modern word editor, like tracked changes and comments.

# 2. The Future of Collaborative Writing

What might this look like in practice? Let’s do some quick examples of what we can embed with Quarto—just to illustrate how writing meets data. Imagine each chunk of code is hidden from those who don't need it, but they can still rearrange or comment on the output.

## 2.1 A Simple R-Driven Figure

```{r basic-plot, echo=FALSE, fig.cap="MPG vs. HP in mtcars"}
library(ggplot2)

ggplot(mtcars, aes(x = hp, y = mpg)) +
  geom_point(color = "steelblue", size=3) +
  geom_smooth(method="lm", color="orange", se=FALSE) +
  theme_minimal() +
  labs(
    title = "Miles per Gallon vs. Horsepower",
    x = "Horsepower",
    y = "Miles per Gallon"
  )
```

For the coder: trivial. For the writing-oriented collaborator: they just see a neat scatter plot. They can rename the caption, move the figure, or add commentary. They don’t even need to see how the sausage (code) was made.

## 2.2 A Table of Summaries

```{r summary-table, echo=FALSE, results='asis'}
library(dplyr)
library(knitr)

sum_table <- mtcars %>%
  group_by(cyl) %>%
  summarise(
    count = n(),
    avg_mpg = mean(mpg),
    avg_hp = mean(hp)
  )

kable(sum_table, caption = "Summary of mtcars by Cylinder Count")
```

Again, for the coder: “Sure, I group by `cyl` and do some summarizing.” For the writing collaborator: “Great, I see a summary table; let me rephrase the caption, reorder the columns if needed.” They never have to worry about R syntax.

## 2.3 Standalone Math

$$
\text{Bernoulli's Principle: } P + \tfrac{1}{2}\rho v^2 + \rho g h = \text{constant}
$$

We’re not writing LaTeX by hand in front of them; that’s behind the scenes. They see a crisp formula. If they want to add some words around it, they can.

# 3. Embracing the Best of Both Worlds

So where does this conversation lead us?

-   **We Don’t Need Another Format**: `.ipynb` and `.qmd` are fine. They do what we want: integrate code, text, references, analysis.
-   **We Do Want a More Welcoming Interface**: Something that hides technical overhead from those who just want to handle the final doc’s logic, structure, or language.

### 3.1 A Think Piece, Not a Product Pitch

This is not about pitching yet another tool as much as it is about **envisioning** how we could bring analysis, as understood in the sciences, and analysis as uncderstood in the humanities, closer together.

1.  A real-time environment that displays `.ipynb` or `.qmd` files in a Word-processor-like interface.
2.  One-click toggles to show or hide code blocks—**for those who care**.
3.  Inline collaboration and commentary, with suggestions and track-changes, across code + text.

# 4. Toward a Frictionless Collaboration

When writing is truly collaborative, **both** the code-literate and code-averse folks can stay in sync. One might tweak a statistical approach, another rewrites paragraphs for clarity. The synergy fosters better results because:

-   **Domain experts** can correct interpretations or highlight real-world implications.\
-   **Data experts** can keep the analysis accurate and up-to-date in the same file.\
-   **Language experts** ensure top-notch clarity and polish.

All without stepping on each other’s toes or needing a messy set of doc exports.

## 4.1 A Quick Extra Analysis

Here’s one more snippet: analyzing correlation of numeric columns in `mtcars`, just to show another code-output scenario.

```{r corr-heatmap, echo=FALSE, fig.cap="Correlation among numeric columns of mtcars"}
library(psych)

nums <- mtcars[, sapply(mtcars, is.numeric)]
c_res <- corr.test(nums)

df_heat <- as.data.frame(as.table(c_res$r))

ggplot(df_heat, aes(Var1, Var2, fill=Freq)) +
  geom_tile(color="white") +
  scale_fill_gradient2(low="blue", high="red", mid="white", midpoint=0, limit=c(-1,1)) +
  theme_minimal() +
  labs(title="Correlation Heatmap (mtcars)", x="", y="")
```

-   Coders: “This is normal code stuff.”\
-   Non-coders: “Oh, a neat heatmap. I want to rename the y-axis or tweak the legend. Let me do that from a user-friendly menu or side panel.”

# 5. Final Thoughts

**Writing** has always been about blending ideas and narratives. **Data-driven** writing just ups the stakes: we want code, figures, references, and text to live together. If we want a truly inclusive environment for all collaborators—**coders and non-coders**—then the future of literate programming must be about removing barriers. We keep `.ipynb`, `.qmd`, etc., but wrap them in a frictionless interface that empowers everyone.

> In the end, it’s not about replacing the notebook or Quarto—it’s about acknowledging that writing, especially scientific writing, is a team sport. And teams have all sorts of players. Let’s invite them all to the same field, with a common language they can actually use.